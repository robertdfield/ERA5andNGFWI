#
# This fetches ERA5Land single point time series for coordinates in a csv files for a list of variables.
# So far, that table has mostly been a coarse grid of points in a csv generated by a MATLAB script. 

# More info about the data here: 
# https://cds.climate.copernicus.eu/datasets/reanalysis-era5-land-timeseries?tab=overview
#
# There are also instructions for API setup and downloading using the 'cdsapi' (Climate Data Store API)
# https://cds.climate.copernicus.eu/how-to-api
#
# It's nice to do a manual data selection and fetch to get the underlying data fetch python code. 
#
# This script was built by putting for loops around that kind of code/
#
# By robert.field@columbia.edu
#

import os
import csv
import cdsapi
import logging
import sys


# main local computer location. Change this according to where you'd like your output on your machine
machineRoot = "/Users/rfield1/data/observations/"

# name of dataset
#dataset = "reanalysis-era5-land-timeseries"
dataset = "reanalysis-era5-land-timeseries"


# provide csv file with list of points to fetch. This could be anything really, with an ID, latitude and longitude variable specified in the loop below

# this, for example, is a list of fire locations
#coordFN = machineRoot + "FEDS/LOCAL/NRT_Europe_West_Siberia_20201125_PM_lf_perimeter.fgb_20250401_20251231.nRegions.2.csv"

# this is a list of grid points that I made in another script
#regionName = "WestIberianPeninsula"

regionName = 'IberianPeninsula'
outputRoot = machineRoot + "ERA5Land/" + dataset + "/" + regionName + "/"
coordFN = outputRoot + regionName + ".gridSpacingDegrees.0.25.DownloadCoords.csv"

# this would be better if the string was constructed from two date variables
#dateRangeString = "1950-01-02/2025-12-31"
dateRangeString = "1980-01-01/2025-12-31"

#
# All definitions and settings etc above here please
#

# By default the API displays a LOT of messages
# Tried to log INFO messages rather than display them on each call
# This did not work. Try again sometime...
#logging.basicConfig(filename = outputRoot + "logfile.txt")
#logger = logging.getLogger("cdsapi")
# only log really bad events
#logger.setLevel(logging.ERROR)

# make the output directories if they doesn't exist. Maybe this can be done once, but I seem to have to do each directory and subdirectory
if not os.path.exists(machineRoot):
   os.mkdir(machineRoot)
if not os.path.exists(outputRoot):
   os.mkdir(outputRoot)
   
# read the coordinates in the csv
with open(coordFN, newline='') as csvfile:
    coordinateTable = csv.DictReader(csvfile)
    for row in coordinateTable:
        # get current coordinates and an ID to name output files with. 
        # variable names could be modified. It would be a good idea someday to replace these hard-coded variable names with variables whose values are set above 

#       # this is for that fire location file 
#        currID = row['fireID']
#        currLatCentroid = row['lat_centroid']
#        currLonCentroid = row['lon_centroid']

        currID = row['ID']
        currLatCentroid = row['Lat']
        currLonCentroid = row['Lon']
        
        # print out info for current centroid
        print(currID,currLatCentroid,currLonCentroid)
        
        # make location to store output for 'currID'. There could be a lot of coordinates in coordinateTable, so it's nice to split the files up like this
        outputDir = outputRoot + "/" + currID + "/"
        if not os.path.exists(outputDir):
            os.mkdir(outputDir)
        
        # Set up the download request in the cdsapi format
        #
        # Do a manual data fetch and look a the API code it makes to understand where this comes from
        #
        # The returned file has lat/lon for each row. This is very redundant and the data are elswehere. It probably doubles the file size. It would be nice to omit this.
        #
        # It also groups some of the output variables in files, with a processing ID stamp, which is dealt with by whatever program is reading these files
        request = {
           "variable": ["2m_temperature","2m_dewpoint_temperature","surface_pressure","total_precipitation","surface_solar_radiation_downwards","snow_cover","10m_u_component_of_wind","10m_v_component_of_wind","volumetric_soil_water_level_1","volumetric_soil_water_level_2","volumetric_soil_water_level_3","volumetric_soil_water_level_4"],
           "location": {"longitude": str(currLonCentroid), "latitude": str(currLatCentroid)},
           "date": [dateRangeString],
           "data_format": "csv"
        }
            
        # output file name
        target = outputDir + currID + ".zip"
        print(target)
            
        # fetch the data if it doesn't already exist
        if not os.path.exists(target):
            client = cdsapi.Client()
            client.retrieve(dataset, request,target)
                
            # check that it was downloaded. For now, want to see the reason
            if not os.path.exists(target):
                print(target + " not properly downloaded")                
        else:
            print("already exists")
	
	

	


